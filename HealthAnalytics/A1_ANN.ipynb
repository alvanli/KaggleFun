{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ivAif3NlcbtE",
    "outputId": "7d1211fb-835c-42c4-91a7-a3d6d026862a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "/root\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "%cd root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "colab_type": "code",
    "id": "sOCSeNfQcUM1",
    "outputId": "01177b6d-0299-418f-d81a-c53a3f055354"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Hospital_type_code</th>\n",
       "      <th>City_Code_Hospital</th>\n",
       "      <th>Hospital_region_code</th>\n",
       "      <th>Available Extra Rooms in Hospital</th>\n",
       "      <th>Department</th>\n",
       "      <th>Ward_Type</th>\n",
       "      <th>Ward_Facility_Code</th>\n",
       "      <th>Bed Grade</th>\n",
       "      <th>City_Code_Patient</th>\n",
       "      <th>Type of Admission</th>\n",
       "      <th>Severity of Illness</th>\n",
       "      <th>Visitors with Patient</th>\n",
       "      <th>Age</th>\n",
       "      <th>Admission_Deposit</th>\n",
       "      <th>Stay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>231676</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6247.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>166821</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70566</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4987.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>197982</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7210.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>280389</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3178.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Hospital_type_code  ...  Admission_Deposit  Stay\n",
       "0      231676                   0  ...             6247.0     2\n",
       "1      166821                   0  ...             8000.0    10\n",
       "2       70566                   1  ...             4987.0     1\n",
       "3      197982                   1  ...             7210.0     6\n",
       "4      280389                   3  ...             3178.0     5\n",
       "\n",
       "[5 rows x 16 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "base_dir = \"\"\n",
    "df_train = pd.read_csv(os.path.join(base_dir,\"pro_train.csv\"))\n",
    "df_test = pd.read_csv(os.path.join(base_dir,\"pro_test.csv\"))\n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "wha9HzDHcUM8",
    "outputId": "d647a1af-2b2c-4564-9dab-f4ff5eb9ee12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 5\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "cats = [\"Hospital_type_code\",\"City_Code_Hospital\",\"Hospital_region_code\",\"Department\",\"City_Code_Patient\", \"Ward_Type\", \"Ward_Facility_Code\", \"Type of Admission\"]\n",
    "nums = [\"Severity of Illness\", \"Age\", \"Bed Grade\", \"Admission_Deposit\", \"Visitors with Patient\"]\n",
    "print(len(cats), len(nums))\n",
    "print(len(df_train.columns))\n",
    "# stay and unnamed are dropped, 16 - 2 = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "JhFGCs-ycUM_",
    "outputId": "ed2e9bf4-1084-4890-fc68-0dba1582429f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
       "              handle_unknown='error', sparse=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "sc=StandardScaler()\n",
    "sc.fit(df_train.copy().drop(columns=cats+[\"Stay\",\"Unnamed: 0\"]))\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "oh = OneHotEncoder()\n",
    "oh.fit(df_train.Stay.to_numpy().reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "pWPBEKNxcUNB",
    "outputId": "1602ce36-b3cb-4acc-98da-b0c5e8865710"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, 4), (14, 6), (3, 2), (5, 3), (39, 19), (6, 3), (6, 3), (3, 2)]"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_sizes = [(int(max(df_train[cat].unique())+1), min(50, (len(df_train[cat].unique())+1)//2)) for cat in cats]\n",
    "embedding_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3StKVrUscUND"
   },
   "outputs": [],
   "source": [
    "df_train = df_train.drop([\"Unnamed: 0\"], axis = 1)\n",
    "df_test = df_test.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F4NIVxTOcUNJ"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class TabDataset(Dataset):\n",
    "    def __init__(self, df, cats):\n",
    "        self.x_cat = df.loc[:,cats].copy().values.astype(np.int64) #categorical columns\n",
    "        self.x_num = sc.transform(df.drop(columns=cats+[\"Stay\"]).copy()).astype(np.float32) #numerical columns\n",
    "        self.y = oh.transform(df.Stay.to_numpy().reshape(-1,1)).toarray()\n",
    "    def __len__(self): \n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x_cat[idx], self.x_num[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hWaW0C78cUNM"
   },
   "outputs": [],
   "source": [
    "train_data = TabDataset(df_train, cats)\n",
    "test_data = TabDataset(df_test, cats)\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size, drop_last = True)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y54kZ2fccUNP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, embedding_sizes, n_cont):\n",
    "        super().__init__()\n",
    "        self.n_cont = n_cont\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(categories, size) for categories,size in embedding_sizes])\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeddings) #length of all embeddings combined\n",
    "        self.emb_drop = nn.Dropout(0.6)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        self.n_emb, self.n_cont = n_emb, n_cont\n",
    "        self.linearBlock = nn.Sequential(\n",
    "            nn.Linear(self.n_emb + self.n_cont, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256,128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(128,64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64,11)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        x_1 = [em(x1[:,i]) for i, em in enumerate(self.embeddings)]\n",
    "            \n",
    "        x_1 = torch.cat(x_1, axis = 1)\n",
    "        x_1 = self.emb_drop(x_1)\n",
    "        x_2 = self.bn1(x2)\n",
    "        \n",
    "        x = torch.cat([x_1, x_2], axis = 1)\n",
    "        y = self.linearBlock(x)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "colab_type": "code",
    "id": "PdJ7WgdTcUNR",
    "outputId": "887dd32f-d725-41d4-c92e-8f9f6b35ac7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "ANN(\n",
      "  (embeddings): ModuleList(\n",
      "    (0): Embedding(7, 4)\n",
      "    (1): Embedding(14, 6)\n",
      "    (2): Embedding(3, 2)\n",
      "    (3): Embedding(5, 3)\n",
      "    (4): Embedding(39, 19)\n",
      "    (5): Embedding(6, 3)\n",
      "    (6): Embedding(6, 3)\n",
      "    (7): Embedding(3, 2)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.6, inplace=False)\n",
      "  (bn1): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (linearBlock): Sequential(\n",
      "    (0): Linear(in_features=48, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): Dropout(p=0.4, inplace=False)\n",
      "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): Dropout(p=0.4, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): Dropout(p=0.2, inplace=False)\n",
      "    (9): Linear(in_features=64, out_features=11, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model = ANN(embedding_sizes, 6)\n",
    "model.to(device)\n",
    "lr=0.05\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "epochs = 100\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "46vLqRZNcUNT"
   },
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)   \n",
    "    y_test_num = torch.argmax(y_test, axis=1)\n",
    "    correct_pred = (y_pred_tags == y_test_num).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    \n",
    "    return acc*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "lpBJ7u_fcUNV",
    "outputId": "7d482199-a277-4100-bc79-fa2d6b890537",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Acc: 10.50, Val Acc: 17.23\n",
      "Epoch: 1, Acc: 35.50, Val Acc: 36.25\n",
      "Epoch: 2, Acc: 39.50, Val Acc: 36.18\n",
      "Epoch: 3, Acc: 32.50, Val Acc: 36.50\n",
      "Epoch: 4, Acc: 31.50, Val Acc: 36.01\n",
      "Epoch: 5, Acc: 34.50, Val Acc: 36.25\n",
      "Epoch: 6, Acc: 35.50, Val Acc: 35.78\n",
      "Epoch: 7, Acc: 28.00, Val Acc: 33.46\n",
      "Epoch: 8, Acc: 33.00, Val Acc: 36.35\n",
      "Epoch: 9, Acc: 32.50, Val Acc: 34.26\n",
      "Epoch: 10, Acc: 32.50, Val Acc: 33.05\n",
      "Epoch: 11, Acc: 36.00, Val Acc: 36.01\n",
      "Epoch: 12, Acc: 36.50, Val Acc: 35.48\n",
      "Epoch: 13, Acc: 37.00, Val Acc: 36.52\n",
      "Epoch: 14, Acc: 37.50, Val Acc: 35.55\n",
      "Epoch: 15, Acc: 36.50, Val Acc: 36.59\n",
      "Epoch: 16, Acc: 34.50, Val Acc: 36.09\n",
      "Epoch: 17, Acc: 31.50, Val Acc: 36.47\n",
      "Epoch: 18, Acc: 28.50, Val Acc: 32.18\n",
      "Epoch: 19, Acc: 29.50, Val Acc: 34.84\n",
      "Epoch: 20, Acc: 34.50, Val Acc: 35.03\n",
      "Epoch: 21, Acc: 35.50, Val Acc: 34.37\n",
      "Epoch: 22, Acc: 39.50, Val Acc: 36.61\n",
      "Epoch: 23, Acc: 33.50, Val Acc: 36.89\n",
      "Epoch: 24, Acc: 34.50, Val Acc: 35.55\n",
      "Epoch: 25, Acc: 43.00, Val Acc: 35.70\n",
      "Epoch: 26, Acc: 41.50, Val Acc: 35.54\n",
      "Epoch: 27, Acc: 39.50, Val Acc: 36.40\n",
      "Epoch: 28, Acc: 38.50, Val Acc: 35.44\n",
      "Epoch: 29, Acc: 37.50, Val Acc: 33.69\n",
      "Epoch: 30, Acc: 34.00, Val Acc: 36.85\n",
      "Epoch: 31, Acc: 32.50, Val Acc: 36.95\n",
      "Epoch: 32, Acc: 37.50, Val Acc: 35.81\n",
      "Epoch: 33, Acc: 31.00, Val Acc: 35.02\n",
      "Epoch: 34, Acc: 38.00, Val Acc: 35.93\n",
      "Epoch: 35, Acc: 40.00, Val Acc: 36.12\n",
      "Epoch: 36, Acc: 33.50, Val Acc: 34.23\n",
      "Epoch: 37, Acc: 35.00, Val Acc: 36.43\n",
      "Epoch: 38, Acc: 37.00, Val Acc: 36.47\n",
      "Epoch: 39, Acc: 39.50, Val Acc: 35.30\n",
      "Epoch: 40, Acc: 36.50, Val Acc: 36.73\n",
      "Epoch: 41, Acc: 39.00, Val Acc: 36.55\n",
      "Epoch: 42, Acc: 38.50, Val Acc: 34.52\n",
      "Epoch: 43, Acc: 35.00, Val Acc: 36.35\n",
      "Epoch: 44, Acc: 32.50, Val Acc: 35.15\n",
      "Epoch: 45, Acc: 37.50, Val Acc: 36.13\n",
      "Epoch: 46, Acc: 30.00, Val Acc: 34.67\n",
      "Epoch: 47, Acc: 39.50, Val Acc: 37.40\n",
      "Epoch: 48, Acc: 30.50, Val Acc: 36.33\n",
      "Epoch: 49, Acc: 41.00, Val Acc: 37.32\n",
      "Epoch: 50, Acc: 30.00, Val Acc: 35.28\n",
      "Epoch: 51, Acc: 39.00, Val Acc: 36.86\n",
      "Epoch: 52, Acc: 40.00, Val Acc: 35.11\n",
      "Epoch: 53, Acc: 39.00, Val Acc: 36.40\n",
      "Epoch: 54, Acc: 35.50, Val Acc: 36.48\n",
      "Epoch: 55, Acc: 36.50, Val Acc: 36.81\n",
      "Epoch: 56, Acc: 40.50, Val Acc: 36.28\n",
      "Epoch: 57, Acc: 34.00, Val Acc: 35.04\n",
      "Epoch: 58, Acc: 30.00, Val Acc: 36.00\n",
      "Epoch: 59, Acc: 34.50, Val Acc: 36.12\n",
      "Epoch: 60, Acc: 36.00, Val Acc: 36.90\n",
      "Epoch: 61, Acc: 38.50, Val Acc: 35.23\n",
      "Epoch: 62, Acc: 35.00, Val Acc: 36.42\n",
      "Epoch: 63, Acc: 38.00, Val Acc: 36.07\n",
      "Epoch: 64, Acc: 37.00, Val Acc: 35.61\n",
      "Epoch: 65, Acc: 35.00, Val Acc: 36.95\n",
      "Epoch: 66, Acc: 38.00, Val Acc: 36.99\n",
      "Epoch: 67, Acc: 32.50, Val Acc: 36.47\n",
      "Epoch: 68, Acc: 31.00, Val Acc: 36.33\n",
      "Epoch: 69, Acc: 31.00, Val Acc: 34.13\n",
      "Epoch: 70, Acc: 35.00, Val Acc: 35.11\n",
      "Epoch: 71, Acc: 33.00, Val Acc: 36.16\n",
      "Epoch: 72, Acc: 43.00, Val Acc: 37.42\n",
      "Epoch: 73, Acc: 39.50, Val Acc: 35.65\n",
      "Epoch: 74, Acc: 36.00, Val Acc: 35.72\n",
      "Epoch: 75, Acc: 31.00, Val Acc: 35.97\n",
      "Epoch: 76, Acc: 38.50, Val Acc: 36.11\n",
      "Epoch: 77, Acc: 36.50, Val Acc: 36.21\n",
      "Epoch: 78, Acc: 38.00, Val Acc: 35.38\n",
      "Epoch: 79, Acc: 34.50, Val Acc: 34.97\n",
      "Epoch: 80, Acc: 39.00, Val Acc: 36.44\n",
      "Epoch: 81, Acc: 32.50, Val Acc: 36.28\n",
      "Epoch: 82, Acc: 34.00, Val Acc: 35.31\n",
      "Epoch: 83, Acc: 39.50, Val Acc: 35.89\n",
      "Epoch: 84, Acc: 33.00, Val Acc: 35.20\n",
      "Epoch: 85, Acc: 37.50, Val Acc: 35.66\n",
      "Epoch: 86, Acc: 34.50, Val Acc: 35.18\n",
      "Epoch: 87, Acc: 38.50, Val Acc: 36.47\n",
      "Epoch: 88, Acc: 33.50, Val Acc: 35.69\n",
      "Epoch: 89, Acc: 37.00, Val Acc: 35.56\n",
      "Epoch: 90, Acc: 40.50, Val Acc: 36.56\n",
      "Epoch: 91, Acc: 36.00, Val Acc: 35.00\n",
      "Epoch: 92, Acc: 38.00, Val Acc: 36.92\n",
      "Epoch: 93, Acc: 39.00, Val Acc: 35.90\n",
      "Epoch: 94, Acc: 38.00, Val Acc: 36.96\n",
      "Epoch: 95, Acc: 33.00, Val Acc: 36.28\n",
      "Epoch: 96, Acc: 35.00, Val Acc: 34.25\n",
      "Epoch: 97, Acc: 36.00, Val Acc: 35.48\n",
      "Epoch: 98, Acc: 36.00, Val Acc: 36.27\n",
      "Epoch: 99, Acc: 39.00, Val Acc: 36.57\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "loss_min = np.inf\n",
    "for i in range(epochs):\n",
    "    for batch_idx, (x1, x2, y) in enumerate(train_loader):\n",
    "        x1, x2, y = x1.to(device), x2.to(device), y.to(device)\n",
    "        model.zero_grad()\n",
    "        output = model(x1, x2)\n",
    "        loss = criterion(output, torch.argmax(y, axis=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx == 0:\n",
    "            test_acc = []\n",
    "            for xx1, xx2, yy in test_loader:\n",
    "              xx1, xx2, yy = xx1.to(device), xx2.to(device), yy.to(device)\n",
    "              model.zero_grad()\n",
    "              yyout = model(xx1, xx2)\n",
    "              test_acc.append(multi_acc(yyout, yy).detach().cpu().numpy())\n",
    "            print(\"Epoch: {}, Acc: {:.2f}, Val Acc: {:.2f}\".format(i, multi_acc(output, y), np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The highest is 43% train acc, 37% test acc"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "A1_ANN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
